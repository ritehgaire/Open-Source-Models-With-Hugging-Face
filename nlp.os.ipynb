{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748ebf47-c01a-47b0-987d-f8aa0f99e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (4.37.2)\n",
      "Requirement already satisfied: torch in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (2.2.0.post100)\n",
      "Requirement already satisfied: filelock in /Users/riteshgaire/.local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f370989-db02-462e-b4e5-2f12eb2ec4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4fc086-47b4-4907-9d37-c8112bb214ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04e1d8f27d442408afeb82ae87b0c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3c3f675f24400abd5c98d5064a4c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0b8eabf302487ba4875e91cb605d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/62.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174de14a619e4f62a3b3870e284d0aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e606204863a3456e8605a94f54d67b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94626ce94e76417a88b66e78a702003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/310k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984efdb879f04c87b8009b8df9517291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c021dd3352046cc896a420701105e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/730M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e5b2fbf2db4cde9b81f90ff0586c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained('facebook/blenderbot-400M-distill')\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained('facebook/blenderbot-400M-distill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e077e21-24ae-4196-9fdc-cd22565d4362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm doing well, thank you. How are you this fine evening? Do you have any plans?\n"
     ]
    }
   ],
   "source": [
    "# Input text\n",
    "input_text = \"Hello, how are you?\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a response\n",
    "reply_ids = model.generate(**inputs)\n",
    "\n",
    "# Decode the response\n",
    "reply = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the response\n",
    "print(reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63b0c0-8ba0-44d9-ab6f-8b907c3bf265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hello, how is things\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blenderbot:  Things are good. How are you? I am just relaxing after a long day at work.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  nice to hear that, do you have any plans tonight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blenderbot:  I am going to watch a movie with my girlfriend. I am really looking forward to it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  can you do maths\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blenderbot:  I can, but I'm not sure if I'm good at it. I've never been good at math.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  sam was 10m when his brother was 8m at the age of 50, now sam is 15m at the age of 75, and his brother passed away at the age if 70, how long is sam's brother at the age of 75?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blenderbot:  I'm not sure, but I do know that Sam's brother is the youngest of three siblings.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input_text = input(\"You: \")\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(**inputs)\n",
    "    reply = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "    print(f\"Blenderbot: {reply}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e26ebe-4145-4875-92e7-0000912a8959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
