{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14351b9-f985-4cc1-ba40-5ad271140b09",
   "metadata": {},
   "source": [
    "Cell 1: Import necessary libraries and set up logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80a8ba-c4a9-418a-b05d-72e6d3d98d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5150181f-6dc6-4e2b-90ed-55fd0724f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.2.0.post100)\n",
      "Requirement already satisfied: numpy in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/riteshgaire/.local/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/riteshgaire/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.0.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915793a3-5356-4fbb-a659-ba4d75cc1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import logging utilities to control the verbosity of the output from transformers\n",
    "from transformers.utils import logging\n",
    "\n",
    "# Set logging level to only display errors to keep the output clean\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Import the SentenceTransformer class to load the pre-trained model\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0cc520-2bb0-46cc-8a9e-2ab2a7a771a7",
   "metadata": {},
   "source": [
    "Cell 2: Loading the model and encoding the first set of sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3928d51d-73c5-4fba-be76-eacdd4fd24d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db59d89f8bbe460983f03eff9fddcfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba0282b17bf4fe093ed6760fec23b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b37ad4d2ed6401b95d5be791ece72ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba9ab0c6d594cbfb37afb6039745050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40013d048e98481ea9b1f01fd068b0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3803e1cc52184e1a998b40337da622f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5c13e6744c48e0ab8555a8a370793e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5299d66a3049474a905858f0da557efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8652d6479aca44e6ae5756a8e5827a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e13971d6b74609a235e6a1c3e555e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28e9ca74453427a8b0446fc7b6d5320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1392,  0.0030,  0.0470,  ...,  0.0641, -0.0163,  0.0636],\n",
      "        [ 0.0227, -0.0014, -0.0056,  ..., -0.0225,  0.0846, -0.0283],\n",
      "        [-0.1043, -0.0628,  0.0093,  ...,  0.0020,  0.0653, -0.0150]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained 'all-MiniLM-L6-v2' model from Hugging Face's Sentence-Transformers library\n",
    "# This model generates sentence embeddings for natural language processing tasks\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Define the first set of sentences to generate embeddings\n",
    "sentences1 = ['The cat sits outside',\n",
    "              'A man is playing guitar',\n",
    "              'The movies are awesome']\n",
    "\n",
    "# Encode the first set of sentences into embeddings\n",
    "# The parameter 'convert_to_tensor=True' ensures that the output is a tensor, suitable for PyTorch operations\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "\n",
    "# Print the embeddings to verify that the model has processed the sentences\n",
    "print(embeddings1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbad59-25a0-4b27-b6bb-e0bbd3a02201",
   "metadata": {},
   "source": [
    "Cell 3: Encoding the second set of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f5c6fb-90a5-4da1-8f8c-8aa792d8e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0163, -0.0700,  0.0384,  ...,  0.0447,  0.0254, -0.0023],\n",
      "        [ 0.0054, -0.0920,  0.0140,  ...,  0.0167, -0.0086, -0.0424],\n",
      "        [-0.0842, -0.0592, -0.0010,  ..., -0.0157,  0.0764,  0.0389]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Define the second set of sentences to generate embeddings\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "# Encode the second set of sentences into embeddings\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# Print the embeddings to verify that the model has processed the sentences\n",
    "print(embeddings2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50dc0d-f191-4be0-a6a5-dcb6b02f5967",
   "metadata": {},
   "source": [
    "Cell 4: Computing cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "174972f0-9771-4c11-a286-8e7bdac92b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2838,  0.1310, -0.0029],\n",
      "        [ 0.2277, -0.0327, -0.0136],\n",
      "        [-0.0124, -0.0465,  0.6571]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Import the utility functions from the sentence_transformers library\n",
    "from sentence_transformers import util\n",
    "\n",
    "# Compute cosine similarity between the two sets of sentence embeddings\n",
    "# This will generate a similarity score for each pair of sentences from the two sets\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "# Print the cosine similarity matrix\n",
    "print(cosine_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949b4da-6570-4e0e-9e6d-3af79c719494",
   "metadata": {},
   "source": [
    "Cell 5: Displaying individual cosine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f2414d-7d9d-4908-94fc-e239638c8efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The movies are awesome \t\t The new movie is so great \t\t Score: 0.6571\n"
     ]
    }
   ],
   "source": [
    "# Loop over the length of sentences1 to print the cosine similarity for each sentence pair\n",
    "# {:.4f} formats the score to 4 decimal places for readability\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i],\n",
    "                                                 sentences2[i],\n",
    "                                                 cosine_scores[i][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817ec75-c4f3-4234-a4f1-1b5f81cf1bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
